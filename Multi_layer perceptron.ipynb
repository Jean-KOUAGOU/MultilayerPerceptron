{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return torch.tanh(x)\n",
    "    \n",
    "def dsigma(x):\n",
    "    return (1-torch.tanh(x)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(x,y):\n",
    "    return torch.norm(x-y)**2\n",
    "\n",
    "def dloss(x,y):\n",
    "    return 2*(x-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Forward and backward passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(w1, b1, w2, b2, x):\n",
    "    s1=torch.mm(w1, x)+b1\n",
    "    x1=sigma(s1)\n",
    "    s2=torch.mm(w2, x1)+b2\n",
    "    x2=sigma(s2)\n",
    "    return x, s1, x1, s2, x2\n",
    "    \n",
    "def backward_pass(w1, b1, w2, b2, t, x, s1, x1, s2, x2, dl_dw1, dl_db1, dl_dw2, dl_db2):\n",
    "    dl_dx2=dloss(x2, t)\n",
    "    dl_dx1=torch.mm(w2.T, dloss(x2, t)) * dsigma(s2)\n",
    "    dx1_dw1=dsigma(s1) * x.T\n",
    "    dx2_ds2=dsigma(s2)\n",
    "    dl_ds2=dx2_ds2*dl_dx2\n",
    "    dl_ds1=dl_dx1*dsigma(s1)\n",
    "    #gradients\n",
    "    dl__dw1=torch.mm(dl_dx1,dx1_dw1)\n",
    "    dl__dw2=torch.mm(dl_ds2, x1.T)\n",
    "    dl__db1=dl_ds1\n",
    "    dl__db2=dl_ds2\n",
    "    \n",
    "    return dl__dw1, dl__dw2, dl__db1, dl__db2\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, s1, x1, s2, x2 = forward(w1, b1, w2, b2, train_input[0].unsqueeze(1))\n",
    "# t=torch.randn(x2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward_pass(w1, b1, w2, b2, t, x, s1, x1, s2, x2, dl_dw1, dl_db1, dl_dw2, dl_db2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "from  dlc_practical_prologue import load_data\n",
    "train_input, train_target, test_input, test_target = load_data(one_hot_labels = True, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target=train_target*0.9\n",
    "test_target=test_target*0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt, numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f955655b490>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_input.unsqueeze(1)[14].view(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(x):\n",
    "    idx=x.argmax(dim=1)\n",
    "    pred=torch.zeros_like(x)\n",
    "    pred[torch.arange(x.size(0)), idx]=0.9\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0/400, training loss : 0.810, test loss : 0.810, accu_train : 9.70%, accu_test : 8.50%\n",
      "Epoch : 10/400, training loss : 0.739, test loss : 0.731, accu_train : 11.70%, accu_test : 9.90%\n",
      "Epoch : 20/400, training loss : 0.739, test loss : 0.730, accu_train : 11.70%, accu_test : 9.90%\n",
      "Epoch : 30/400, training loss : 0.739, test loss : 0.728, accu_train : 26.10%, accu_test : 21.80%\n",
      "Epoch : 40/400, training loss : 0.742, test loss : 0.627, accu_train : 32.20%, accu_test : 29.50%\n",
      "Epoch : 50/400, training loss : 0.496, test loss : 0.603, accu_train : 53.10%, accu_test : 47.60%\n",
      "Epoch : 60/400, training loss : 0.453, test loss : 0.601, accu_train : 59.40%, accu_test : 55.90%\n",
      "Epoch : 70/400, training loss : 0.369, test loss : 0.668, accu_train : 72.00%, accu_test : 66.30%\n",
      "Epoch : 80/400, training loss : 0.288, test loss : 0.776, accu_train : 77.00%, accu_test : 70.60%\n",
      "Epoch : 90/400, training loss : 0.251, test loss : 0.719, accu_train : 81.80%, accu_test : 73.00%\n",
      "Epoch : 100/400, training loss : 0.298, test loss : 0.791, accu_train : 82.00%, accu_test : 70.40%\n",
      "Epoch : 110/400, training loss : 0.320, test loss : 0.663, accu_train : 87.50%, accu_test : 76.00%\n",
      "Epoch : 120/400, training loss : 0.261, test loss : 0.789, accu_train : 88.10%, accu_test : 76.30%\n",
      "Epoch : 130/400, training loss : 0.343, test loss : 0.728, accu_train : 85.90%, accu_test : 73.00%\n",
      "Epoch : 140/400, training loss : 0.309, test loss : 0.609, accu_train : 87.70%, accu_test : 76.00%\n",
      "Epoch : 150/400, training loss : 0.265, test loss : 0.677, accu_train : 87.90%, accu_test : 76.30%\n",
      "Epoch : 160/400, training loss : 0.202, test loss : 0.636, accu_train : 88.40%, accu_test : 75.30%\n",
      "Epoch : 170/400, training loss : 0.306, test loss : 0.706, accu_train : 89.80%, accu_test : 76.50%\n",
      "Epoch : 180/400, training loss : 0.182, test loss : 0.790, accu_train : 90.30%, accu_test : 78.80%\n",
      "Epoch : 190/400, training loss : 0.302, test loss : 0.872, accu_train : 88.20%, accu_test : 76.40%\n",
      "Epoch : 200/400, training loss : 0.213, test loss : 0.813, accu_train : 88.60%, accu_test : 75.60%\n",
      "Epoch : 210/400, training loss : 0.270, test loss : 0.750, accu_train : 90.30%, accu_test : 76.60%\n",
      "Epoch : 220/400, training loss : 0.225, test loss : 0.553, accu_train : 88.80%, accu_test : 76.30%\n",
      "Epoch : 230/400, training loss : 0.214, test loss : 0.705, accu_train : 91.20%, accu_test : 78.30%\n",
      "Epoch : 240/400, training loss : 0.280, test loss : 0.711, accu_train : 90.90%, accu_test : 75.40%\n",
      "Epoch : 250/400, training loss : 0.227, test loss : 0.889, accu_train : 88.80%, accu_test : 74.80%\n",
      "Epoch : 260/400, training loss : 0.378, test loss : 0.757, accu_train : 88.60%, accu_test : 74.10%\n",
      "Epoch : 270/400, training loss : 0.195, test loss : 0.670, accu_train : 90.50%, accu_test : 75.90%\n",
      "Epoch : 280/400, training loss : 0.198, test loss : 0.653, accu_train : 91.20%, accu_test : 76.50%\n",
      "Epoch : 290/400, training loss : 0.287, test loss : 0.902, accu_train : 88.60%, accu_test : 73.70%\n",
      "Epoch : 300/400, training loss : 0.221, test loss : 0.668, accu_train : 91.50%, accu_test : 77.10%\n",
      "Epoch : 310/400, training loss : 0.248, test loss : 0.620, accu_train : 91.90%, accu_test : 76.50%\n",
      "Epoch : 320/400, training loss : 0.270, test loss : 0.780, accu_train : 91.60%, accu_test : 77.10%\n",
      "Epoch : 330/400, training loss : 0.156, test loss : 0.576, accu_train : 93.30%, accu_test : 77.70%\n",
      "Epoch : 340/400, training loss : 0.206, test loss : 0.657, accu_train : 92.80%, accu_test : 78.10%\n",
      "Epoch : 350/400, training loss : 0.149, test loss : 0.662, accu_train : 92.00%, accu_test : 74.20%\n",
      "Epoch : 360/400, training loss : 0.447, test loss : 0.877, accu_train : 89.30%, accu_test : 72.50%\n",
      "Epoch : 370/400, training loss : 0.169, test loss : 0.924, accu_train : 90.00%, accu_test : 73.80%\n",
      "Epoch : 380/400, training loss : 0.182, test loss : 0.674, accu_train : 92.40%, accu_test : 75.80%\n",
      "Epoch : 390/400, training loss : 0.238, test loss : 0.724, accu_train : 92.60%, accu_test : 77.30%\n"
     ]
    }
   ],
   "source": [
    "eps=1e-6\n",
    "w1=torch.normal(mean=torch.zeros((50, 784)), std=torch.ones((50, 784))*eps)\n",
    "w2=torch.normal(mean=torch.zeros((10, 50)), std=torch.ones((10, 50))*eps)\n",
    "b1=torch.normal(mean=torch.zeros((50, 1)), std=torch.ones((50, 1))*eps)\n",
    "b2=torch.normal(mean=torch.zeros((10, 1)), std=torch.ones((10, 1))*eps)\n",
    "\n",
    "dl_dw1=torch.zeros_like(w1)\n",
    "dl_dw2=torch.zeros_like(w2)\n",
    "dl_db1=torch.zeros_like(b1)\n",
    "dl_db2=torch.zeros_like(b2)\n",
    "\n",
    "num_epoch=400\n",
    "lr=1e-4\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    sum_dl_dw1=torch.zeros_like(dl_dw1)\n",
    "    sum_dl_dw2=torch.zeros_like(dl_dw2)\n",
    "    sum_dl_db1=torch.zeros_like(dl_db1)\n",
    "    sum_dl_db2=torch.zeros_like(dl_db2)\n",
    "    X2=[]\n",
    "    X2_t1=[]\n",
    "    for idx in range(train_input.size(0)):\n",
    "        x=train_input[idx].unsqueeze(1)\n",
    "        t=train_target[idx].unsqueeze(1)\n",
    "        t1=test_target[idx].unsqueeze(1)\n",
    "        x_t1=test_input[idx].unsqueeze(1)\n",
    "        _, s1, x1, s2, x2 = forward(w1, b1, w2, b2, x)\n",
    "        X2.append(x2.T)\n",
    "        _, _, _, _, x2_t1=forward(w1, b1, w2, b2, x_t1)\n",
    "        dl_dw1, dl_dw2, dl_db1, dl_db2 = backward_pass(w1, b1, w2, b2, t, x, s1, x1, s2, x2, dl_dw1, dl_db1, dl_dw2, dl_db2)\n",
    "        X2_t1.append(x2_t1)\n",
    "        sum_dl_dw1 += dl_dw1\n",
    "        sum_dl_dw2 += dl_dw2\n",
    "        sum_dl_db1 += dl_db1\n",
    "        sum_dl_db2 += dl_db2\n",
    "        \n",
    "    X2 = torch.stack(X2, dim=0).squeeze()\n",
    "    X2_t1 = torch.stack(X2_t1, dim=0).squeeze()\n",
    "    \n",
    "    w1 -= lr*sum_dl_dw1\n",
    "    w2 -= lr*sum_dl_dw2\n",
    "    b1 -= lr*sum_dl_db1\n",
    "    b2 -= lr*sum_dl_db2\n",
    "    \n",
    "    accuracy2 = ((prediction(X2_t1) == test_target).all(dim=1)*1.0).mean()\n",
    "#     if accuracy2>0.78:\n",
    "#         lr=lr/1.1 #this will reduce the learning rate when good accuracy is achieved in order to avoid overfitting and divergence\n",
    "        \n",
    "    if i%10 == 0:\n",
    "        accuracy1 = ((prediction(X2) == train_target).all(dim=1)*1.0).mean()\n",
    "        accuracy2 = ((prediction(X2_t1) == test_target).all(dim=1)*1.0).mean()\n",
    "        print(\"Epoch : {}/{}, training loss : {:.3f}, test loss : {:.3f}, accu_train : {:.2f}%, accu_test : {:.2f}%\".format(i, num_epoch, \\\n",
    "                                                           loss(x2, t), loss(x2_t1, t1), accuracy1*100, accuracy2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 7, 4, 0, 9, 1,\n",
       "        5, 2, 4, 3, 2, 7, 3, 8, 6, 7, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,\n",
       "        5, 3, 3, 0, 7, 4, 9, 7, 0, 9, 4, 1, 4, 4, 6, 0, 4, 5, 6, 1, 0, 0, 1, 7,\n",
       "        1, 6, 3, 0, 2, 1, 1, 7, 7, 0, 2, 6, 7, 8, 3, 7, 0, 4, 6, 7, 4, 6, 8, 0,\n",
       "        7, 8, 3, 1, 9, 7, 1, 7, 1, 1, 6, 3, 0, 6, 9, 3, 1, 1, 0, 4, 9, 2, 0, 0,\n",
       "        2, 0, 2, 7, 1, 8, 6, 4, 1, 6, 3, 4, 5, 7, 5, 3, 3, 1, 5, 4, 7, 7, 4, 2,\n",
       "        8, 5, 8, 6, 7, 3, 4, 6, 1, 9, 7, 6, 0, 3, 7, 2, 7, 2, 9, 4, 4, 6, 4, 9,\n",
       "        7, 0, 9, 2, 7, 5, 1, 5, 9, 1, 2, 3, 7, 3, 5, 9, 1, 7, 6, 2, 8, 2, 2, 5,\n",
       "        0, 7, 4, 9, 7, 8, 3, 2, 1, 1, 5, 3, 6, 1, 0, 3, 1, 0, 0, 1, 7, 2, 7, 3,\n",
       "        0, 4, 6, 5, 2, 6, 4, 7, 7, 8, 9, 9, 5, 0, 7, 1, 6, 2, 0, 3, 5, 4, 6, 5,\n",
       "        1, 6, 3, 7, 5, 8, 0, 9, 1, 0, 7, 1, 2, 2, 3, 3, 6, 4, 7, 5, 0, 6, 0, 7,\n",
       "        9, 8, 5, 9, 7, 1, 1, 4, 4, 5, 6, 4, 1, 2, 6, 3, 9, 3, 9, 0, 5, 9, 6, 5,\n",
       "        7, 4, 1, 3, 4, 0, 4, 8, 0, 4, 3, 6, 1, 7, 6, 0, 9, 7, 5, 7, 2, 1, 1, 6,\n",
       "        8, 9, 4, 1, 5, 2, 2, 9, 0, 3, 4, 6, 7, 2, 0, 3, 5, 4, 3, 6, 5, 8, 9, 5,\n",
       "        4, 7, 4, 2, 7, 3, 4, 8, 9, 1, 5, 2, 5, 7, 9, 1, 5, 7, 4, 1, 3, 1, 1, 0,\n",
       "        2, 3, 9, 4, 9, 2, 1, 6, 8, 4, 1, 7, 4, 4, 9, 2, 5, 7, 2, 4, 4, 2, 1, 9,\n",
       "        7, 2, 8, 7, 6, 9, 2, 2, 3, 8, 1, 6, 5, 1, 1, 0, 2, 6, 4, 5, 5, 3, 1, 5,\n",
       "        1, 9, 2, 7, 4, 4, 4, 8, 1, 5, 5, 9, 5, 6, 7, 9, 9, 2, 7, 0, 9, 0, 6, 6,\n",
       "        2, 3, 4, 0, 7, 5, 4, 8, 0, 9, 4, 1, 1, 8, 7, 1, 2, 6, 1, 0, 3, 0, 1, 1,\n",
       "        8, 2, 0, 7, 9, 4, 0, 5, 0, 6, 1, 7, 7, 8, 1, 9, 1, 0, 5, 1, 2, 2, 7, 3,\n",
       "        5, 4, 9, 7, 1, 9, 3, 9, 1, 0, 3, 1, 1, 2, 0, 3, 5, 7, 6, 8, 7, 9, 5, 8,\n",
       "        5, 7, 6, 1, 1, 3, 1, 7, 5, 5, 5, 2, 5, 5, 7, 0, 9, 7, 7, 5, 0, 7, 0, 0,\n",
       "        2, 9, 2, 4, 8, 4, 6, 1, 6, 5, 1, 5, 3, 4, 0, 5, 3, 8, 3, 6, 2, 3, 9, 2,\n",
       "        1, 1, 5, 2, 1, 3, 2, 5, 7, 5, 7, 2, 4, 6, 9, 7, 2, 4, 2, 8, 1, 1, 1, 8,\n",
       "        4, 0, 6, 5, 9, 3, 0, 9, 2, 4, 7, 1, 1, 7, 4, 2, 6, 1, 8, 9, 0, 6, 6, 7,\n",
       "        9, 9, 5, 0, 1, 4, 4, 6, 7, 1, 5, 1, 0, 3, 5, 8, 4, 7, 1, 2, 5, 9, 5, 6,\n",
       "        7, 5, 4, 8, 8, 3, 6, 9, 7, 0, 7, 2, 7, 1, 1, 0, 7, 9, 2, 3, 1, 3, 1, 4,\n",
       "        1, 6, 2, 7, 5, 5, 7, 4, 0, 2, 6, 3, 6, 4, 0, 4, 2, 6, 0, 0, 0, 0, 2, 1,\n",
       "        6, 2, 2, 3, 1, 4, 1, 5, 4, 6, 4, 7, 2, 8, 7, 9, 2, 0, 5, 1, 4, 2, 8, 3,\n",
       "        2, 4, 1, 5, 4, 6, 0, 7, 9, 8, 4, 9, 8, 0, 1, 1, 0, 2, 2, 3, 2, 4, 4, 5,\n",
       "        1, 6, 5, 7, 7, 8, 5, 9, 7, 4, 7, 3, 2, 0, 8, 6, 8, 6, 1, 6, 8, 9, 4, 0,\n",
       "        7, 0, 4, 1, 5, 4, 7, 5, 3, 7, 4, 9, 8, 5, 8, 6, 3, 8, 6, 9, 9, 1, 8, 3,\n",
       "        5, 8, 6, 5, 9, 7, 2, 5, 0, 8, 4, 1, 1, 0, 9, 1, 2, 6, 7, 0, 9, 3, 0, 8,\n",
       "        8, 9, 6, 7, 8, 4, 7, 5, 9, 2, 6, 7, 4, 5, 9, 2, 3, 1, 6, 3, 9, 2, 2, 5,\n",
       "        6, 8, 0, 7, 7, 1, 9, 8, 7, 0, 4, 9, 4, 6, 2, 8, 5, 1, 4, 1, 5, 5, 1, 7,\n",
       "        3, 6, 4, 3, 2, 5, 6, 4, 4, 0, 6, 4, 6, 7, 9, 4, 3, 3, 1, 0, 0, 3, 2, 2,\n",
       "        7, 8, 2, 3, 7, 0, 1, 1, 0, 2, 3, 3, 8, 4, 3, 2, 7, 6, 4, 7, 2, 8, 5, 9,\n",
       "        7, 0, 3, 1, 1, 2, 4, 3, 4, 4, 7, 5, 9, 6, 2, 0, 7, 1, 4, 2, 7, 3, 6, 7,\n",
       "        5, 8, 4, 5, 5, 2, 7, 1, 1, 5, 6, 8, 5, 8, 4, 0, 7, 9, 9, 2, 9, 7, 7, 8,\n",
       "        7, 4, 2, 6, 9, 1, 7, 0, 6, 4, 8, 5, 7, 0, 7, 1, 0, 3, 7, 6, 5, 0, 6, 1,\n",
       "        5, 1, 7, 8, 5, 0, 3, 4, 7, 7, 5, 7, 8, 6, 9, 3, 8, 6, 1, 0, 9, 7, 1, 3,\n",
       "        0, 5, 6, 4, 4, 2, 4, 4, 3, 1, 7, 4, 6, 0, 3, 6])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(X2).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9240)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((train_target.argmax(dim=1)==prediction(X2).argmax(dim=1))*1.0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7490)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((test_target.argmax(dim=1)==prediction(X2_t1).argmax(dim=1))*1.0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
